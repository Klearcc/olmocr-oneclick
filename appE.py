
import datetime
import os
import torch
import base64
import urllib.request
import tempfile
import gradio as gr
import shutil
from io import BytesIO
from PIL import Image
from transformers import AutoProcessor, Qwen2VLForConditionalGeneration
from PyPDF2 import PdfReader


from olmocr.data.renderpdf import render_pdf_to_base64png
from olmocr.prompts import build_finetuning_prompt
from olmocr.prompts.anchor import get_anchor_text




# ä¿å­˜æˆ–è¿½åŠ å†…å®¹åˆ°txtæ–‡ä»¶
def save_results_to_file(original_filename_with_timestamp, page_result):
    result_path = f"{original_filename_with_timestamp}.txt"
    with open(result_path, "a", encoding='utf-8') as f:
        f.write(f"{page_result}\n\n")
    return result_path


import datetime
import os
from PyPDF2 import PdfReader

def save_results_to_file(original_filename_with_timestamp, page_result):
    result_path = f"{original_filename_with_timestamp}.txt"
    with open(result_path, "a", encoding='utf-8') as f:
        f.write(f"{page_result}\n\n")
    return result_path

def process_single_pdf_realtime(pdf_file, temperature, max_new_tokens, num_return_sequences, do_sample):
    original_file_name = os.path.splitext(os.path.basename(pdf_file.name))[0]
    timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
    original_file_name_with_timestamp = f"{original_file_name}_{timestamp}"
    result_txt_path = f"{original_file_name_with_timestamp}.txt"

    if not pdf_file.name.lower().endswith(".pdf"):
        yield "", f"âŒ æ–‡ä»¶{original_file_name}éPDFæ ¼å¼ï¼"
        return

    try:
        reader = PdfReader(pdf_file.name)
        num_pages = len(reader.pages)
    except Exception as e:
        yield "", f"âŒ æ— æ³•è¯»å–PDFæ–‡ä»¶{original_file_name}é¡µæ•°: {str(e)}"
        return

    with open(result_txt_path, "w", encoding="utf-8") as f_res:
        f_res.write(f"PDFæ–‡ä»¶åç§°ï¼š{original_file_name}.pdfï¼Œå…± {num_pages} é¡µ\n\n")

    cumulative_errors = []

    for page_number in range(1, num_pages + 1):
        try:
            page_text, _img = process_pdf_file(
                pdf_file.name,
                page_number,
                temperature=temperature,
                max_new_tokens=max_new_tokens,
                num_return_sequences=num_return_sequences,
                do_sample=do_sample
            )

            page_output = f"==== ğŸ“„ æ–‡ä»¶ã€{original_file_name}.pdfã€‘ç¬¬ {page_number}/{num_pages} é¡µåˆ†æç»“æœ ====\n{page_text}\n"

            save_results_to_file(original_file_name_with_timestamp, page_output)

            yield page_output, ("âœ… æ— é”™è¯¯" if not cumulative_errors else "\n\n".join(cumulative_errors))

        except Exception as page_error:
            import traceback
            error_details = traceback.format_exc()
            error_msg = f"âŒ æ–‡ä»¶ã€{original_file_name}.pdfã€‘ç¬¬ {page_number}/{num_pages} é¡µåˆ†æå¼‚å¸¸ï¼š{str(page_error)}\nè¯¦æƒ…ï¼š{error_details}\n\n"
            cumulative_errors.append(error_msg)

            save_results_to_file(original_file_name_with_timestamp, error_msg)

            yield "", error_msg

    yield f"\nğŸ“—ğŸ‰ æ–‡ä»¶ã€{original_file_name}.pdfã€‘åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨{result_txt_path}\n", ("âœ… æ— é”™è¯¯" if not cumulative_errors else "\n\n".join(cumulative_errors))


                     
def process_entire_file_upload_with_progress(file,
                               temperature=0.8,
                               max_new_tokens=50,
                               num_return_sequences=1,
                               do_sample=True):
    try:
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.name)[1])
        temp_file.close()
        shutil.copy(file.name, temp_file.name)

        file_extension = os.path.splitext(temp_file.name)[1].lower()

        if file_extension == ".pdf":
            # ä½¿ç”¨ä¸Šè¿°æ–°yieldå‡½æ•°ï¼ˆå¸¦è¿›åº¦ï¼‰
            for result, errors in process_entire_pdf_with_progress(
                            temp_file.name,
                            temperature,
                            max_new_tokens,
                            num_return_sequences,
                            do_sample,
                        ):
                yield result, errors
        else:
            yield "", "âŒ ä»…æ”¯æŒå¤„ç†PDFæ–‡ä»¶ï¼Œè¯·é‡æ–°ä¸Šä¼ PDFæ ¼å¼çš„æ–‡ä»¶ï¼"

        os.unlink(temp_file.name)

    except Exception as e:
        import traceback
        yield "", f"âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}\n{traceback.format_exc()}"



def process_entire_pdf_with_progress(pdf_path, temperature=0.8, max_new_tokens=50, num_return_sequences=1, do_sample=True):
    outputs = []
    errors = []

    try:
        reader = PdfReader(pdf_path)
        num_pages = len(reader.pages)
    except Exception as e:
        yield "", f"âŒè·å–é¡µæ•°æ—¶å‡ºé”™ï¼š{str(e)}"
        return

    for page_number in range(1, num_pages + 1):
        try:
            text_output, _ = process_pdf_file(
                pdf_path,
                page_number,
                temperature,
                max_new_tokens,
                num_return_sequences,
                do_sample,
            )
            outputs.append(f"==== ç¬¬ {page_number}/{num_pages} é¡µ ====\n{text_output}\n")
        except Exception as page_error:
            import traceback
            error_msg = f"ç¬¬ {page_number} é¡µ âŒ é”™è¯¯: {str(page_error)}\nè¯¦ç»†ä¿¡æ¯:\n{traceback.format_exc()}"
            errors.append(error_msg)

        # æ¯å¤„ç†å®Œä¸€é¡µï¼Œyieldè¾“å‡ºå¹¶å®æ—¶å±•ç¤ºé¡µé¢è¿›åº¦ 
        current_progress = "\n".join(outputs)
        current_error_log = "\n\n".join(errors) if errors else "âœ… æ— é”™è¯¯"
        yield current_progress, current_error_log

    # æœ€åå†yieldä¸€æ¬¡ç¡®ä¿å®Œæ•´æ€§ï¼ˆå¤„ç†å®Œæ¯•ï¼‰
    final_output = "\n".join(outputs)
    final_errors = "\n\n".join(errors) if errors else "âœ… æ— é”™è¯¯"
    yield final_output, final_errors



def process_entire_file_upload(file,
                               temperature=0.8,
                               max_new_tokens=50,
                               num_return_sequences=1,
                               do_sample=True):
    try:
        # ä¸´æ—¶ä¿å­˜PDFæ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(
            delete=False, suffix=os.path.splitext(file.name)[1]
        )
        temp_file.close()
        shutil.copy(file.name, temp_file.name)

        # ç¡®è®¤æ–‡ä»¶æ‰©å±•å
        file_extension = os.path.splitext(temp_file.name)[1].lower()

        if file_extension == ".pdf":
            # å¤„ç†æ•´ä¸ªPDFï¼Œå¹¶æ•è·é”™è¯¯
            result, errors = process_entire_pdf(
                temp_file.name,
                temperature,
                max_new_tokens,
                num_return_sequences,
                do_sample,
            )
        else:
            result = ""
            errors = "âŒ ä»…æ”¯æŒPDFæ–‡ä»¶ï¼Œè¯·é‡æ–°ä¸Šä¼ æ­£ç¡®æ ¼å¼çš„æ–‡ä»¶ï¼"

        os.unlink(temp_file.name)

        # å¦‚æœæ— é”™è¯¯ä¿¡æ¯ï¼Œè¿”å›"âœ… æ— é”™è¯¯"
        error_output = errors if errors else "âœ… æ— é”™è¯¯"

        return result, error_output

    except Exception as e:
        import traceback
        return "", f"âŒç³»ç»Ÿé”™è¯¯: {str(e)}\n{traceback.format_exc()}"
    

def process_entire_pdf(pdf_path, temperature=0.8, max_new_tokens=50, num_return_sequences=1, do_sample=True):
    outputs = []  # ç”¨æ¥ç´¯ç§¯æ¯é¡µè¾“å‡º
    errors = []   # ç”¨æ¥å­˜å‚¨æ¯é¡µå¯èƒ½å‘ç”Ÿçš„é”™è¯¯ä¿¡æ¯

    # é¦–å…ˆè·å–PDFæ–‡ä»¶é¡µæ•°
    try:
        reader = PdfReader(pdf_path)
        num_pages = len(reader.pages)
    except Exception as e:
        return "", f"è·å–é¡µæ•°æ—¶å‡ºé”™ï¼š{str(e)}"

    for page_number in range(1, num_pages + 1):
        try:
            # è°ƒç”¨ä½ åŸæ¥å·²æœ‰çš„å•é¡µå¤„ç†å‡½æ•°
            text_output, _ = process_pdf_file(
                pdf_path,
                page_number,
                temperature,
                max_new_tokens,
                num_return_sequences,
                do_sample,
            )
            outputs.append(f"===== ç¬¬ {page_number} é¡µ =====\n{text_output}\n")
        except Exception as page_error:
            import traceback
            error_msg = f"ç¬¬ {page_number} é¡µå¤„ç†å‡ºé”™: {str(page_error)}\nè¯¦æƒ…:\n{traceback.format_exc()}"
            errors.append(error_msg)

    # æ‹¼æ¥æ‰€æœ‰è¾“å‡º
    final_output = "\n\n".join(outputs)

    # æ‹¼æ¥æ‰€æœ‰çš„é”™è¯¯ä¿¡æ¯
    final_errors = "\n\n".join(errors)

    return final_output, final_errors


# Initialize the model (globally to avoid reloading it on each request)
print("Initializing the model...")
model = Qwen2VLForConditionalGeneration.from_pretrained(
    "allenai/olmOCR-7B-0225-preview", torch_dtype=torch.bfloat16
).eval()
processor = AutoProcessor.from_pretrained("Qwen/Qwen2-VL-7B-Instruct",use_fast=True)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print(f"Model loaded on {device}")


def download_pdf(url):
    """Download a PDF from the specified URL"""
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
    try:
        urllib.request.urlretrieve(url, temp_file.name)
        return temp_file.name
    except Exception as e:
        return None, f"Error during PDF download: {str(e)}"


def process_pdf_url(
    url,
    page_number=1,
    temperature=0.8,
    max_new_tokens=4096,
    num_return_sequences=1,
    do_sample=True,
):
    """Process a PDF from URL and generate output using olmOCR"""
    try:
        # Download the PDF
        pdf_path = download_pdf(url)
        if pdf_path is None:
            return "Error downloading the PDF", None

        # Process the PDF
        result, image = process_pdf_file(
            pdf_path,
            page_number,
            temperature,
            max_new_tokens,
            num_return_sequences,
            do_sample,
        )

        # Clean up temporary files
        os.unlink(pdf_path)

        return result, image

    except Exception as e:
        import traceback

        return f"Error: {str(e)}\n{traceback.format_exc()}", None


def process_pdf_file(
    pdf_path,
    page_number=1,
    temperature=0.8,
    max_new_tokens=4096,
    num_return_sequences=1,
    do_sample=True,
):
    """Process a local PDF and generate output using olmOCR"""
    try:
        # Render the PDF page as an image
        image_base64 = render_pdf_to_base64png(
            pdf_path, page_number, target_longest_image_dim=1024
        )

        # Process the PDF with the generated base64
        return process_pdf_base64(
            image_base64,
            pdf_path,
            page_number,
            temperature,
            max_new_tokens,
            num_return_sequences,
            do_sample,
        )

    except Exception as e:
        import traceback

        return f"Error: {str(e)}\n{traceback.format_exc()}", None


def process_file_upload(
    file,
    page_number=1,
    temperature=0.8,
    max_new_tokens=50,
    num_return_sequences=1,
    do_sample=True,
):
    """Process a file (PDF or image) uploaded by the user"""
    try:
        # Save the uploaded file temporarily
        temp_file = tempfile.NamedTemporaryFile(
            delete=False, suffix=os.path.splitext(file.name)[1]
        )
        temp_file.close()
        shutil.copy(file.name, temp_file.name)

        # Determine if it's a PDF or an image
        file_extension = os.path.splitext(temp_file.name)[1].lower()

        if file_extension == ".pdf":
            # Process as PDF
            result, image = process_pdf_file(
                temp_file.name,
                page_number,
                temperature,
                max_new_tokens,
                num_return_sequences,
                do_sample,
            )
        elif file_extension in [
            ".jpg",
            ".jpeg",
            ".png",
            ".bmp",
            ".tiff",
            ".tif",
            ".webp",
        ]:
            # Process as image
            result, image = process_image_file(
                temp_file.name,
                temperature,
                max_new_tokens,
                num_return_sequences,
                do_sample,
            )
        else:
            result = f"Unsupported file format: {file_extension}. Please use PDF or images (JPG, PNG, etc.)"
            image = None

        # Clean up temporary files
        os.unlink(temp_file.name)

        return result, image

    except Exception as e:
        import traceback

        return f"Error: {str(e)}\n{traceback.format_exc()}", None


def process_image_file(
    image_path,
    temperature=0.8,
    max_new_tokens=50,
    num_return_sequences=1,
    do_sample=True,
):
    """Process a local image and generate output using olmOCR"""
    try:
        # Open the image
        with open(image_path, "rb") as img_file:
            img_data = img_file.read()
            image_base64 = base64.b64encode(img_data).decode("utf-8")

        # Use a generic anchor text for images
        anchor_text = "Image analysis."

        # Process the image with the generated base64
        return process_pdf_base64(
            image_base64,
            None,  # No PDF path
            1,  # Not applicable for images
            temperature,
            max_new_tokens,
            num_return_sequences,
            do_sample,
            anchor_text=anchor_text,
        )

    except Exception as e:
        import traceback

        return f"Error: {str(e)}\n{traceback.format_exc()}", None


def process_pdf_base64(
    image_base64,
    pdf_path=None,
    page_number=1,
    temperature=0.8,
    max_new_tokens=50,
    num_return_sequences=1,
    do_sample=True,
    anchor_text=None,
):
    """Process an image in base64 format and generate output using olmOCR"""
    try:
        # If a PDF path was provided, get the anchor text
        if pdf_path and not anchor_text:
            anchor_text = get_anchor_text(
                pdf_path, page_number, pdf_engine="pdfreport", target_length=4000
            )
        elif not anchor_text:
            # If we don't have a PDF or a specified anchor text, use a generic anchor text
            anchor_text = "Document analysis."

        prompt = build_finetuning_prompt(anchor_text)

        # Build the complete prompt
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{image_base64}"},
                    },
                ],
            }
        ]

        # Apply the chat template and processor
        text = processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        main_image = Image.open(BytesIO(base64.b64decode(image_base64)))

        # Display the image
        rendered_image = main_image.copy()

        inputs = processor(
            text=[text],
            images=[main_image],
            padding=True,
            return_tensors="pt",
        )
        inputs = {key: value.to(device) for (key, value) in inputs.items()}

        # Generate the output
        output = model.generate(
            **inputs,
            temperature=temperature,
            max_new_tokens=max_new_tokens,
            num_return_sequences=num_return_sequences,
            do_sample=do_sample,
        )

        # Decode the output
        prompt_length = inputs["input_ids"].shape[1]
        new_tokens = output[:, prompt_length:]
        text_output = processor.tokenizer.batch_decode(
            new_tokens, skip_special_tokens=True
        )

        return text_output[0], rendered_image

    except Exception as e:
        import traceback

        return f"Error: {str(e)}\n{traceback.format_exc()}", None


# Create the Gradio interface
with gr.Blocks(title="olmOCR Document Analyzer") as demo:
    gr.Markdown("# olmOCR Document Analyzer")
    gr.Markdown("Analyze PDF documents and images using the olmOCR-7B model")

    with gr.Tabs() as tabs:
        with gr.TabItem("PDF URL"):
            with gr.Row():
                with gr.Column(scale=2):
                    url_input = gr.Textbox(
                        label="PDF URL",
                        placeholder="https://example.com/document.pdf",
                    )
                    page_number_url = gr.Number(
                        label="Page Number", value=1, minimum=1, step=1
                    )

                    with gr.Row():
                        with gr.Column():
                            temperature_url = gr.Slider(
                                label="Temperature",
                                minimum=0.0,
                                maximum=1.0,
                                value=0.8,
                                step=0.1,
                            )
                            max_new_tokens_url = gr.Slider(
                                label="Max New Tokens",
                                minimum=10,
                                maximum=4096,
                                value=1024,
                                step=10,
                            )

                        with gr.Column():
                            num_return_sequences_url = gr.Slider(
                                label="Number of Returned Sequences",
                                minimum=1,
                                maximum=5,
                                value=1,
                                step=1,
                            )
                            do_sample_url = gr.Checkbox(label="Do Sample", value=True)

                    submit_btn_url = gr.Button("Analyze PDF", variant="primary")

                with gr.Column(scale=3):
                    with gr.Row():
                        with gr.Column():
                            image_output_url = gr.Image(label="PDF Page", type="pil")

                        with gr.Column():
                            text_output_url = gr.Textbox(label="Result", lines=10)

                submit_btn_url.click(
                    fn=process_pdf_url,
                    inputs=[
                        url_input,
                        page_number_url,
                        temperature_url,
                        max_new_tokens_url,
                        num_return_sequences_url,
                        do_sample_url,
                    ],
                    outputs=[text_output_url, image_output_url],
                )

                gr.Markdown("### Example URL")
                gr.Examples(
                    examples=[
                        ["https://molmo.allenai.org/paper.pdf", 1, 0.8, 50, 1, True],
                    ],
                    inputs=[
                        url_input,
                        page_number_url,
                        temperature_url,
                        max_new_tokens_url,
                        num_return_sequences_url,
                        do_sample_url,
                    ],
                )

        with gr.TabItem("å¤„ç†å¤šä¸ªPDFæ–‡ä»¶ï¼ˆé€é¡µå®æ—¶åˆ†æ+ä¿å­˜ç»“æœï¼‰"):
            with gr.Row():
                with gr.Column(scale=2):
                    files_input = gr.Files(
                        label="ä¸Šä¼ å¤šä¸ªPDFæ–‡ä»¶",
                        file_types=[".pdf"]
                    )

                    with gr.Row():
                        with gr.Column():
                            temperature_file = gr.Slider(0, 1, value=0.8, step=0.1, label="Temperature")
                            max_new_tokens_file = gr.Slider(10, 4096, value=1024, step=10, label="Max New Tokens")

                        with gr.Column():
                            num_return_sequences_file = gr.Slider(1, 5, value=1, step=1, label="Num Returned Sequences")
                            do_sample_file = gr.Checkbox(value=True, label="Do Sample")

                    submit_btn_files = gr.Button("å¼€å§‹åˆ†æå¤šä¸ªPDFæ–‡ä»¶", variant="primary")

                with gr.Column(scale=3):
                    realtime_result = gr.Textbox(label="ğŸ“„ æ¯ä¸ªæ–‡ä»¶å®æ—¶é€é¡µåˆ†æç»“æœ", lines=25, max_lines=100, interactive=False)
                    realtime_errors = gr.Textbox(label="âš ï¸ é”™è¯¯æ—¥å¿—å®æ—¶æç¤º", lines=10, interactive=False, value="âœ… æ— é”™è¯¯")

                    def analyze_multiple_pdfs(files, temperature, max_new_tokens, num_return_sequences, do_sample):
                        for pdf_file in files:
                            # å¼€å§‹åˆ†ææç¤ºä¿¡æ¯
                            yield f"\n\nğŸ“šâœ¨ å¼€å§‹åˆ†ææ–‡ä»¶ã€{pdf_file.name}ã€‘\n", "âœ… æ— é”™è¯¯"
                            
                            # å¯¹å•ä¸ªpdfæ–‡ä»¶é€é¡µå¤„ç†å¹¶å®æ—¶è¾“å‡ºå•é¡µæœ€æ–°ç»“æœ
                            for page_output, error_info in process_single_pdf_realtime(
                                pdf_file, temperature, max_new_tokens, num_return_sequences, do_sample
                            ):
                                # æ¯å¤„ç†å®Œä¸€é¡µç«‹å³yieldå•é¡µåˆ†æç»“æœï¼Œä¸è¦ç´¯ç§¯å…¨éƒ¨å†å²é¡µå†…å®¹ï¼Œé¿å…å‰ç«¯å¡é¡¿
                                yield page_output, error_info
                            
                            # æ–‡ä»¶å¤„ç†å®Œæˆåçš„æç¤ºä¿¡æ¯
                            yield f"\nğŸ“—ğŸ‰ æ–‡ä»¶ã€{pdf_file.name}ã€‘åˆ†æå®Œæˆï¼\n", error_info

                    # Gradioçš„clickå‡½æ•°æ›¿æ¢ï¼š
                    submit_btn_files.click(
                        fn=analyze_multiple_pdfs,
                        inputs=[files_input, temperature_file, max_new_tokens_file, num_return_sequences_file, do_sample_file],
                        outputs=[realtime_result, realtime_errors]
                    )

        with gr.TabItem("Direct Base64"):
            with gr.Row():
                with gr.Column(scale=2):
                    base64_input = gr.Textbox(
                        label="Enter the base64 string of the image", lines=5
                    )

                    with gr.Row():
                        with gr.Column():
                            temperature_base64 = gr.Slider(
                                label="Temperature",
                                minimum=0.0,
                                maximum=1.0,
                                value=0.8,
                                step=0.1,
                            )
                            max_new_tokens_base64 = gr.Slider(
                                label="Max New Tokens",
                                minimum=10,
                                maximum=4096,
                                value=1024,
                                step=10,
                            )

                        with gr.Column():
                            num_return_sequences_base64 = gr.Slider(
                                label="Number of Returned Sequences",
                                minimum=1,
                                maximum=5,
                                value=1,
                                step=1,
                            )
                            do_sample_base64 = gr.Checkbox(
                                label="Do Sample", value=True
                            )

                    submit_btn_base64 = gr.Button("Analyze Image", variant="primary")

                with gr.Column(scale=3):
                    with gr.Row():
                        with gr.Column():
                            image_output_base64 = gr.Image(
                                label="Decoded Image", type="pil"
                            )

                        with gr.Column():
                            text_output_base64 = gr.Textbox(label="Result", lines=10)

                submit_btn_base64.click(
                    fn=lambda b64, t, m, n, d: process_pdf_base64(
                        b64, None, 1, t, m, n, d
                    ),
                    inputs=[
                        base64_input,
                        temperature_base64,
                        max_new_tokens_base64,
                        num_return_sequences_base64,
                        do_sample_base64,
                    ],
                    outputs=[text_output_base64, image_output_base64],
                )

# Launch the app
if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", share=True)
